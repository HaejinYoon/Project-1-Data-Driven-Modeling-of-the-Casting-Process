#ë² ì´ìŠ¤ ëª¨ë¸ 1

# import pandas as pd
# import numpy as np
# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
# from sklearn.linear_model import LogisticRegression
# from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
# from sklearn.preprocessing import StandardScaler
# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, f1_score, precision_score, recall_score
# import matplotlib.pyplot as plt
# import seaborn as sns
# import warnings

# # XGBoostì™€ LightGBM
# try:
#     import xgboost as xgb
#     XGBOOST_AVAILABLE = True
# except ImportError:
#     XGBOOST_AVAILABLE = False

# try:
#     import lightgbm as lgb
#     LIGHTGBM_AVAILABLE = True
# except ImportError:
#     LIGHTGBM_AVAILABLE = False

# warnings.filterwarnings('ignore')

# # í•œê¸€ í°íŠ¸ ì„¤ì •
# plt.rcParams['font.family'] = 'Malgun Gothic'
# plt.rcParams['axes.unicode_minus'] = False

# print("ğŸ¯ ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì¤‘ì‹¬ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸")
# print("="*60)

# # 1. ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ì •ë³´ í™•ì¸
# print("ğŸ“ ì›ë³¸ ë°ì´í„° ë¡œë”©...")
# train_raw = pd.read_csv('./data/train.csv')

# print(f"âœ… ì›ë³¸ ë°ì´í„°: {train_raw.shape}")
# print(f"ğŸ“Š ì›ë³¸ í´ë˜ìŠ¤ ë¶„í¬:")

# if 'passorfail' in train_raw.columns:
#     original_counts = train_raw['passorfail'].value_counts().sort_index()
#     total_count = len(train_raw)
#     good_count = original_counts.get(0, 0)
#     defect_count = original_counts.get(1, 0)
#     defect_rate = defect_count / total_count * 100
    
#     print(f"   ğŸ“ˆ ì „ì²´: {total_count:,}ê°œ")
#     print(f"   âœ… ì–‘í’ˆ(0): {good_count:,}ê°œ ({good_count/total_count*100:.1f}%)")
#     print(f"   âŒ ë¶ˆëŸ‰í’ˆ(1): {defect_count:,}ê°œ ({defect_count/total_count*100:.1f}%)")
#     print(f"   ğŸ¯ ì›ë³¸ ë¶ˆëŸ‰ë¥ : {defect_rate:.2f}%")
# else:
#     print("âŒ 'passorfail' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
#     exit()

# # 2. ğŸ² ì „ì²´ ë°ì´í„°ë¥¼ ì˜ ì„ì–´ì„œ train/test ë¶„í•  (8:2)
# print(f"\nğŸ² ì „ì²´ ë°ì´í„° ì„ì–´ì„œ train/test ë¶„í•  (8:2)...")

# # ì¸µí™” ì¶”ì¶œë¡œ ë¶ˆëŸ‰ë¥  ìœ ì§€í•˜ë©° ë¶„í• 
# X_raw = train_raw.drop('passorfail', axis=1)
# y_raw = train_raw['passorfail']

# X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(
#     X_raw, y_raw, 
#     test_size=0.2, 
#     random_state=42, 
#     stratify=y_raw,
#     shuffle=True  # ì˜ ì„ê¸°
# )

# print(f"âœ… ë¶„í•  ì™„ë£Œ:")
# print(f"   ğŸ”§ Train: {len(X_train_raw):,}ê°œ")
# train_defect_rate = (y_train_raw == 1).sum() / len(y_train_raw) * 100
# print(f"      ë¶ˆëŸ‰ë¥ : {train_defect_rate:.2f}% ({(y_train_raw == 1).sum():,}ê°œ)")

# print(f"   ğŸ§ª Test: {len(X_test_raw):,}ê°œ") 
# test_defect_rate = (y_test_raw == 1).sum() / len(y_test_raw) * 100
# print(f"      ë¶ˆëŸ‰ë¥ : {test_defect_rate:.2f}% ({(y_test_raw == 1).sum():,}ê°œ)")

# # 3. ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
# def preprocess_data(X, data_name):
#     """ë°ì´í„° ì „ì²˜ë¦¬"""
#     print(f"\nğŸ”§ {data_name} ì „ì²˜ë¦¬...")
#     X_processed = X.copy()
    
#     print(f"   ğŸ“Š ì „ì²˜ë¦¬ ì „: {X_processed.shape}")
    
#     # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
#     drop_columns = ['id', 'line', 'name', 'mold_name', 'registration_time', 'time', 'date']
#     existing_drop_columns = [col for col in drop_columns if col in X_processed.columns]
    
#     if existing_drop_columns:
#         print(f"   ğŸ—‘ï¸ ì œê±°í•  ì»¬ëŸ¼: {existing_drop_columns}")
#         X_processed = X_processed.drop(columns=existing_drop_columns)
    
#     # ê²°ì¸¡ì¹˜ í™•ì¸
#     missing_info = X_processed.isnull().sum()
#     missing_cols = missing_info[missing_info > 0].head(10)
#     if len(missing_cols) > 0:
#         print(f"   ğŸ” ì£¼ìš” ê²°ì¸¡ì¹˜:")
#         for col, count in missing_cols.items():
#             print(f"      {col}: {count:,}ê°œ ({count/len(X_processed)*100:.1f}%)")
    
#     # íŠ¹ì • ì»¬ëŸ¼ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
#     if 'heating_furnace' in X_processed.columns:
#         before = X_processed['heating_furnace'].isnull().sum()
#         X_processed['heating_furnace'].fillna('C', inplace=True)
#         print(f"      âœ… heating_furnace: {before}ê°œ â†’ 'C'ë¡œ ëŒ€ì²´")
    
#     if 'tryshot_signal' in X_processed.columns:
#         before = X_processed['tryshot_signal'].isnull().sum()
#         X_processed['tryshot_signal'].fillna('0', inplace=True)
#         print(f"      âœ… tryshot_signal: {before}ê°œ â†’ '0'ìœ¼ë¡œ ëŒ€ì²´")
    
#     # ë‚¨ì€ ê²°ì¸¡ì¹˜ ì œê±°
#     before_drop = len(X_processed)
#     X_processed = X_processed.dropna()
#     after_drop = len(X_processed)
#     dropped = before_drop - after_drop
    
#     if dropped > 0:
#         print(f"   âš ï¸ dropnaë¡œ {dropped:,}í–‰ ì œê±° ({dropped/before_drop*100:.1f}%)")
    
#     # ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ ì¶”ê°€ ì œê±°
#     datetime_cols = []
#     for col in X_processed.columns:
#         if X_processed[col].dtype == 'object':
#             sample_vals = X_processed[col].dropna().head(3).astype(str).tolist()
#             has_date_pattern = any(
#                 len(val) >= 8 and ('-' in val or '/' in val or ':' in val)
#                 for val in sample_vals
#             )
#             if has_date_pattern:
#                 datetime_cols.append(col)
    
#     if datetime_cols:
#         print(f"   ğŸ—‘ï¸ ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ ì œê±°: {datetime_cols}")
#         X_processed = X_processed.drop(columns=datetime_cols)
    
#     # ë²”ì£¼í˜• ë³€ìˆ˜ ì›í•« ì¸ì½”ë”©
#     categorical_cols = []
#     for col in X_processed.columns:
#         if X_processed[col].dtype == 'object':
#             unique_count = X_processed[col].nunique()
#             if unique_count <= 50:  # 50ê°œ ì´í•˜ë§Œ ì¸ì½”ë”©
#                 categorical_cols.append(col)
#             else:
#                 print(f"   âš ï¸ {col}: ê³ ìœ ê°’ {unique_count}ê°œë¡œ ì¸ì½”ë”© ì œì™¸")
    
#     if categorical_cols:
#         print(f"   ğŸ·ï¸ ì›í•« ì¸ì½”ë”©: {categorical_cols}")
#         X_processed = pd.get_dummies(X_processed, columns=categorical_cols, drop_first=True)
    
#     # ë¹„ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì œê±°
#     non_numeric = X_processed.select_dtypes(exclude=['number']).columns.tolist()
#     if non_numeric:
#         print(f"   ğŸ—‘ï¸ ë¹„ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì œê±°: {non_numeric}")
#         X_processed = X_processed.drop(columns=non_numeric)
    
#     print(f"   âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {X_processed.shape}")
#     return X_processed

# # 4. Train/Test ê°ê° ì „ì²˜ë¦¬
# X_train_processed = preprocess_data(X_train_raw, "Train")
# X_test_processed = preprocess_data(X_test_raw, "Test")

# # ì „ì²˜ë¦¬ í›„ ì‹¤ì œ ë‚¨ì€ ë°ì´í„°ì˜ y ê°’ë“¤ (ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­)
# y_train_processed = y_train_raw.loc[X_train_processed.index]
# y_test_processed = y_test_raw.loc[X_test_processed.index]

# print(f"\nğŸ“Š ì „ì²˜ë¦¬ í›„ ìµœì¢… ë°ì´í„°:")
# print(f"   ğŸ”§ Train: {X_train_processed.shape}, ë¶ˆëŸ‰ë¥ : {(y_train_processed==1).sum()/len(y_train_processed)*100:.2f}%")
# print(f"   ğŸ§ª Test: {X_test_processed.shape}, ë¶ˆëŸ‰ë¥ : {(y_test_processed==1).sum()/len(y_test_processed)*100:.2f}%")

# # 5. ì»¬ëŸ¼ í†µì¼
# print(f"\nğŸ”„ Train/Test ì»¬ëŸ¼ í†µì¼...")
# train_cols = set(X_train_processed.columns)
# test_cols = set(X_test_processed.columns)

# # ê³µí†µ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
# common_cols = list(train_cols & test_cols)
# print(f"   ğŸ“Š ê³µí†µ ì»¬ëŸ¼: {len(common_cols)}ê°œ")

# X_train_final = X_train_processed[common_cols]
# X_test_final = X_test_processed[common_cols]

# print(f"   âœ… ì»¬ëŸ¼ í†µì¼ ì™„ë£Œ: Train {X_train_final.shape}, Test {X_test_final.shape}")

# # 6. ğŸ¯ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° (Trainë§Œ)
# print(f"\nâš–ï¸ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° (Trainë§Œ)...")

# train_counts = y_train_processed.value_counts().sort_index()
# good_count = train_counts.get(0, 0)
# defect_count = train_counts.get(1, 0)

# print(f"   ğŸ“Š Train ì›ë³¸ ë¶„í¬:")
# print(f"      ì–‘í’ˆ: {good_count:,}ê°œ, ë¶ˆëŸ‰í’ˆ: {defect_count:,}ê°œ")
# print(f"      ë¶ˆëŸ‰ë¥ : {defect_count/(good_count+defect_count)*100:.2f}%")

# # ì–¸ë”ìƒ˜í”Œë§ (6:4 ë¹„ìœ¨ë¡œ ì¡°ì •)
# target_ratio = 0.4  # ë¶ˆëŸ‰í’ˆ ë¹„ìœ¨ì„ 40%ë¡œ
# target_defect_count = defect_count
# target_good_count = int(defect_count / target_ratio * (1 - target_ratio))

# print(f"   ğŸ¯ ëª©í‘œ ë¶„í¬ (ë¶ˆëŸ‰í’ˆ {target_ratio*100:.0f}%):")
# print(f"      ì–‘í’ˆ: {target_good_count:,}ê°œ, ë¶ˆëŸ‰í’ˆ: {target_defect_count:,}ê°œ")

# # ì–¸ë”ìƒ˜í”Œë§ ì‹¤í–‰
# good_indices = y_train_processed[y_train_processed == 0].index
# defect_indices = y_train_processed[y_train_processed == 1].index

# np.random.seed(42)
# sampled_good_indices = np.random.choice(good_indices, target_good_count, replace=False)
# final_indices = np.concatenate([sampled_good_indices, defect_indices])
# np.random.shuffle(final_indices)

# X_train_balanced = X_train_final.loc[final_indices]
# y_train_balanced = y_train_processed.loc[final_indices]

# balanced_counts = y_train_balanced.value_counts().sort_index()
# print(f"   âœ… ê· í˜• ì¡°ì • ì™„ë£Œ:")
# print(f"      ì–‘í’ˆ: {balanced_counts.get(0, 0):,}ê°œ, ë¶ˆëŸ‰í’ˆ: {balanced_counts.get(1, 0):,}ê°œ")
# print(f"      ë¶ˆëŸ‰ë¥ : {balanced_counts.get(1, 0)/len(y_train_balanced)*100:.2f}%")

# # 7. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë“¤ ì •ì˜
# print(f"\nğŸ¤– ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì •ì˜...")

# models = {
#     'Random Forest': RandomForestClassifier(
#         n_estimators=100,
#         max_depth=10,
#         random_state=42,
#         n_jobs=-1,
#         class_weight='balanced'
#     ),
#     'Gradient Boosting': GradientBoostingClassifier(
#         n_estimators=100,
#         learning_rate=0.1,
#         max_depth=6,
#         random_state=42
#     ),
#     'Logistic Regression': LogisticRegression(
#         random_state=42,
#         max_iter=1000,
#         class_weight='balanced'
#     )
# }

# if XGBOOST_AVAILABLE:
#     models['XGBoost'] = xgb.XGBClassifier(
#         n_estimators=100,
#         learning_rate=0.1,
#         max_depth=6,
#         random_state=42,
#         eval_metric='logloss'
#     )

# if LIGHTGBM_AVAILABLE:
#     models['LightGBM'] = lgb.LGBMClassifier(
#         n_estimators=100,
#         learning_rate=0.1,
#         max_depth=6,
#         random_state=42,
#         verbose=-1,
#         class_weight='balanced'
#     )

# print(f"   ğŸ“Š ì´ {len(models)}ê°œ ëª¨ë¸ ì¤€ë¹„")

# # 8. ìŠ¤ì¼€ì¼ë§
# scaler = StandardScaler()
# X_train_scaled = scaler.fit_transform(X_train_balanced)
# X_test_scaled = scaler.transform(X_test_final)

# scaling_models = ['Logistic Regression']

# # 9. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
# print(f"\nğŸ‹ï¸ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€...")
# results = {}

# for name, model in models.items():
#     print(f"\nğŸ”„ {name} í•™ìŠµ...")
    
#     # ìŠ¤ì¼€ì¼ë§ ë°ì´í„° ì„ íƒ
#     if name in scaling_models:
#         X_train_use = X_train_scaled
#         X_test_use = X_test_scaled
#     else:
#         X_train_use = X_train_balanced
#         X_test_use = X_test_final
    
#     # í•™ìŠµ
#     model.fit(X_train_use, y_train_balanced)
    
#     # ì˜ˆì¸¡
#     test_pred = model.predict(X_test_use)
#     test_proba = model.predict_proba(X_test_use)[:, 1] if hasattr(model, 'predict_proba') else None
    
#     # ì„±ëŠ¥ ê³„ì‚°
#     accuracy = accuracy_score(y_test_processed, test_pred)
#     precision = precision_score(y_test_processed, test_pred)
#     recall = recall_score(y_test_processed, test_pred)
#     f1 = f1_score(y_test_processed, test_pred)
    
#     # ğŸ¯ í•µì‹¬: ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì •í™•ë„
#     actual_defect_rate = (y_test_processed == 1).sum() / len(y_test_processed) * 100
#     predicted_defect_rate = (test_pred == 1).sum() / len(test_pred) * 100
#     defect_rate_error = abs(actual_defect_rate - predicted_defect_rate)
    
#     # êµì°¨ê²€ì¦
#     cv_scores = cross_val_score(model, X_train_use, y_train_balanced, cv=5, scoring='accuracy')
    
#     results[name] = {
#         'accuracy': accuracy,
#         'precision': precision,
#         'recall': recall,
#         'f1': f1,
#         'cv_mean': cv_scores.mean(),
#         'cv_std': cv_scores.std(),
#         'actual_defect_rate': actual_defect_rate,
#         'predicted_defect_rate': predicted_defect_rate,
#         'defect_rate_error': defect_rate_error,
#         'predictions': test_pred,
#         'probabilities': test_proba
#     }
    
#     print(f"   âœ… Accuracy: {accuracy:.4f}")
#     print(f"   âœ… Precision: {precision:.4f}")
#     print(f"   âœ… Recall: {recall:.4f}")
#     print(f"   âœ… F1-Score: {f1:.4f}")
#     print(f"   ğŸ¯ ì‹¤ì œ ë¶ˆëŸ‰ë¥ : {actual_defect_rate:.2f}%")
#     print(f"   ğŸ¯ ì˜ˆì¸¡ ë¶ˆëŸ‰ë¥ : {predicted_defect_rate:.2f}%")
#     print(f"   ğŸ¯ ë¶ˆëŸ‰ë¥  ì˜¤ì°¨: {defect_rate_error:.2f}%p")
#     print(f"   ğŸ“Š CV Score: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")

# # 10. ê²°ê³¼ ë¹„êµ ë° ì‹œê°í™”
# print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ...")

# results_df = pd.DataFrame(results).T.round(4)
# results_df = results_df.sort_values('defect_rate_error', ascending=True)  # ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ ê¸°ì¤€ ì •ë ¬

# print(f"\nğŸ† ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì •í™•ë„ ìˆœìœ„:")
# print("="*90)
# print(f"{'ìˆœìœ„':>2} {'ëª¨ë¸':15} {'ì •í™•ë„':>8} {'ì •ë°€ë„':>8} {'ì¬í˜„ìœ¨':>8} {'F1':>6} {'ì‹¤ì œë¶ˆëŸ‰ë¥ ':>8} {'ì˜ˆì¸¡ë¶ˆëŸ‰ë¥ ':>8} {'ì˜¤ì°¨':>6}")
# print("-"*90)

# for i, (model, row) in enumerate(results_df.iterrows(), 1):
#     print(f"{i:2d}. {model:15s} "
#           f"{row['accuracy']:8.4f} "
#           f"{row['precision']:8.4f} "
#           f"{row['recall']:8.4f} "
#           f"{row['f1']:6.4f} "
#           f"{row['actual_defect_rate']:7.2f}% "
#           f"{row['predicted_defect_rate']:7.2f}% "
#           f"{row['defect_rate_error']:5.2f}%p")

# # 11. ìƒì„¸ ì‹œê°í™”
# fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# models_list = list(results.keys())

# # 11-1. ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì •í™•ë„
# ax1 = axes[0, 0]
# actual_rates = [results[m]['actual_defect_rate'] for m in models_list]
# predicted_rates = [results[m]['predicted_defect_rate'] for m in models_list]

# x = np.arange(len(models_list))
# width = 0.35

# ax1.bar(x - width/2, actual_rates, width, label='ì‹¤ì œ ë¶ˆëŸ‰ë¥ ', alpha=0.8, color='red')
# ax1.bar(x + width/2, predicted_rates, width, label='ì˜ˆì¸¡ ë¶ˆëŸ‰ë¥ ', alpha=0.8, color='blue')
# ax1.set_xlabel('ëª¨ë¸')
# ax1.set_ylabel('ë¶ˆëŸ‰ë¥  (%)')
# ax1.set_title('ì‹¤ì œ vs ì˜ˆì¸¡ ë¶ˆëŸ‰ë¥  ë¹„êµ', fontweight='bold')
# ax1.set_xticks(x)
# ax1.set_xticklabels(models_list, rotation=45)
# ax1.legend()
# ax1.grid(axis='y', alpha=0.3)

# # 11-2. ë¶ˆëŸ‰ë¥  ì˜¤ì°¨
# ax2 = axes[0, 1]
# errors = [results[m]['defect_rate_error'] for m in models_list]
# colors = ['green' if e <= 1 else 'orange' if e <= 2 else 'red' for e in errors]

# bars = ax2.bar(range(len(models_list)), errors, color=colors, alpha=0.8)
# ax2.set_xlabel('ëª¨ë¸')
# ax2.set_ylabel('ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ (%p)')
# ax2.set_title('ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì˜¤ì°¨', fontweight='bold')
# ax2.set_xticks(range(len(models_list)))
# ax2.set_xticklabels(models_list, rotation=45)
# ax2.grid(axis='y', alpha=0.3)

# # ê¸°ì¤€ì„  ì¶”ê°€
# ax2.axhline(y=1, color='green', linestyle='--', alpha=0.7, label='ìš°ìˆ˜ (1%p)')
# ax2.axhline(y=2, color='orange', linestyle='--', alpha=0.7, label='ë³´í†µ (2%p)')
# ax2.legend()

# # 11-3. ì •í™•ë„ vs ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ ìŠ¤ìºí„°
# ax3 = axes[0, 2]
# accuracies = [results[m]['accuracy'] for m in models_list]
# scatter = ax3.scatter(errors, accuracies, s=100, alpha=0.7)

# for i, model in enumerate(models_list):
#     ax3.annotate(model, (errors[i], accuracies[i]), 
#                 xytext=(5, 5), textcoords='offset points', fontsize=8)

# ax3.set_xlabel('ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ (%p)')
# ax3.set_ylabel('ì •í™•ë„')
# ax3.set_title('ì •í™•ë„ vs ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì •í™•ë„', fontweight='bold')
# ax3.grid(True, alpha=0.3)

# # 11-4. ìµœê³  ëª¨ë¸ì˜ í˜¼ë™í–‰ë ¬
# best_model = results_df.index[0]
# ax4 = axes[1, 0]

# cm = confusion_matrix(y_test_processed, results[best_model]['predictions'])
# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4,
#             xticklabels=['ì–‘í’ˆ(0)', 'ë¶ˆëŸ‰í’ˆ(1)'], yticklabels=['ì–‘í’ˆ(0)', 'ë¶ˆëŸ‰í’ˆ(1)'])
# ax4.set_title(f'{best_model} - í˜¼ë™í–‰ë ¬', fontweight='bold')
# ax4.set_xlabel('ì˜ˆì¸¡')
# ax4.set_ylabel('ì‹¤ì œ')

# # 11-5. ëª¨ë¸ë³„ F1 ì ìˆ˜
# ax5 = axes[1, 1]
# f1_scores = [results[m]['f1'] for m in models_list]
# bars = ax5.bar(range(len(models_list)), f1_scores, color='lightgreen', alpha=0.8)
# ax5.set_xlabel('ëª¨ë¸')
# ax5.set_ylabel('F1 Score')
# ax5.set_title('ëª¨ë¸ë³„ F1 ì ìˆ˜', fontweight='bold')
# ax5.set_xticks(range(len(models_list)))
# ax5.set_xticklabels(models_list, rotation=45)
# ax5.grid(axis='y', alpha=0.3)

# # 11-6. êµì°¨ê²€ì¦ ì ìˆ˜
# ax6 = axes[1, 2]
# cv_means = [results[m]['cv_mean'] for m in models_list]
# cv_stds = [results[m]['cv_std'] for m in models_list]

# bars = ax6.bar(range(len(models_list)), cv_means, yerr=cv_stds,
#                color='gold', alpha=0.8, capsize=5)
# ax6.set_xlabel('ëª¨ë¸')
# ax6.set_ylabel('CV Score')
# ax6.set_title('êµì°¨ê²€ì¦ ì ìˆ˜', fontweight='bold')
# ax6.set_xticks(range(len(models_list)))
# ax6.set_xticklabels(models_list, rotation=45)
# ax6.grid(axis='y', alpha=0.3)

# plt.tight_layout()
# plt.suptitle('ğŸ¯ ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì¤‘ì‹¬ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ë¹„êµ', fontsize=16, fontweight='bold', y=0.98)
# plt.show()

# # 12. ìµœì¢… ìš”ì•½ ë° ì¶”ì²œ
# print(f"\nğŸ‰ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ë¶„ì„ ì™„ë£Œ!")
# print("="*60)

# best_defect_model = results_df.index[0]
# best_accuracy_model = results_df.sort_values('accuracy', ascending=False).index[0]

# print(f"ğŸ† ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ìµœê³  ëª¨ë¸: {best_defect_model}")
# print(f"   ğŸ¯ ë¶ˆëŸ‰ë¥  ì˜¤ì°¨: {results[best_defect_model]['defect_rate_error']:.2f}%p")
# print(f"   ğŸ“Š ì •í™•ë„: {results[best_defect_model]['accuracy']:.4f}")

# if best_accuracy_model != best_defect_model:
#     print(f"ğŸ¥‡ ì •í™•ë„ ìµœê³  ëª¨ë¸: {best_accuracy_model}")
#     print(f"   ğŸ“Š ì •í™•ë„: {results[best_accuracy_model]['accuracy']:.4f}")
#     print(f"   ğŸ¯ ë¶ˆëŸ‰ë¥  ì˜¤ì°¨: {results[best_accuracy_model]['defect_rate_error']:.2f}%p")

# print(f"\nğŸ“Š ì „ì²´ ìš”ì•½:")
# print(f"   ğŸ“ˆ ì›ë³¸ ë°ì´í„°: {train_raw.shape[0]:,}ê°œ (ë¶ˆëŸ‰ë¥  {defect_rate:.2f}%)")
# print(f"   ğŸ”§ Train ìµœì¢…: {len(y_train_balanced):,}ê°œ (ë¶ˆëŸ‰ë¥  {balanced_counts.get(1,0)/len(y_train_balanced)*100:.2f}%)")
# print(f"   ğŸ§ª Test ìµœì¢…: {len(y_test_processed):,}ê°œ (ë¶ˆëŸ‰ë¥  {actual_defect_rate:.2f}%)")
# print(f"   ğŸ¯ ìµœê³  ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì •í™•ë„: {results_df.iloc[0]['defect_rate_error']:.2f}%p ì˜¤ì°¨")

# print(f"\nğŸ’¾ ì €ì¥ëœ ì£¼ìš” ë³€ìˆ˜:")
# print(f"   - models: í•™ìŠµëœ ëª¨ë¸ë“¤")
# print(f"   - results: ê° ëª¨ë¸ì˜ ìƒì„¸ ê²°ê³¼")
# print(f"   - X_test_final, y_test_processed: í…ŒìŠ¤íŠ¸ ë°ì´í„°")
# print(f"   - scaler: í‘œì¤€í™” ìŠ¤ì¼€ì¼ëŸ¬")

# print(f"\nâœ… ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì™„ë£Œ! ğŸ¯")

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    roc_auc_score, f1_score, precision_score, recall_score
)
from sklearn.utils.class_weight import compute_class_weight
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

# XGBoost, LightGBM ì²´í¬
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

warnings.filterwarnings('ignore')
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

print("ğŸ¯ ë¶ˆê· í˜• í•´ê²° ë°©ë²• ë¹„êµ ë¶„ì„")
print("="*60)

# 1. ë°ì´í„° ë¡œë”©
train_raw = pd.read_csv('./data/train.csv')
print(f"âœ… ì›ë³¸ ë°ì´í„°: {train_raw.shape}")

if 'passorfail' in train_raw.columns:
    original_counts = train_raw['passorfail'].value_counts().sort_index()
    total_count = len(train_raw)
    good_count = original_counts.get(0, 0)
    defect_count = original_counts.get(1, 0)
    defect_rate = defect_count / total_count * 100
    print(f"ğŸ“Š ì›ë³¸ í´ë˜ìŠ¤ ë¶„í¬:")
    print(f"   âœ… ì–‘í’ˆ(0): {good_count:,}ê°œ ({good_count/total_count*100:.1f}%)")
    print(f"   âŒ ë¶ˆëŸ‰í’ˆ(1): {defect_count:,}ê°œ ({defect_count/total_count*100:.1f}%)")
    print(f"   ğŸ¯ ì›ë³¸ ë¶ˆëŸ‰ë¥ : {defect_rate:.2f}%")

# 2. Train/Test Split
X_raw = train_raw.drop('passorfail', axis=1)
y_raw = train_raw['passorfail']

X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(
    X_raw, y_raw,
    test_size=0.2, random_state=42,
    stratify=y_raw, shuffle=True
)

print(f"   ğŸ”§ Train: {len(X_train_raw):,}ê°œ, Test: {len(X_test_raw):,}ê°œ")

# 3. ì „ì²˜ë¦¬ í•¨ìˆ˜ (NaN â†’ ìµœë¹ˆê°’)
def preprocess_data(X, data_name):
    print(f"\nğŸ”§ {data_name} ì „ì²˜ë¦¬...")
    X_processed = X.copy()

    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
    drop_columns = ['id', 'line', 'name', 'mold_name', 'registration_time', 'time', 'date']
    existing_drop_columns = [col for col in drop_columns if col in X_processed.columns]
    if existing_drop_columns:
        X_processed = X_processed.drop(columns=existing_drop_columns)

    # íŠ¹ìˆ˜ ì»¬ëŸ¼ ì±„ìš°ê¸°
    if 'heating_furnace' in X_processed.columns:
        X_processed['heating_furnace'].fillna('C', inplace=True)
    if 'tryshot_signal' in X_processed.columns:
        X_processed['tryshot_signal'].fillna('0', inplace=True)

    # NaN â†’ ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ìš°ê¸°
    imputer = SimpleImputer(strategy='most_frequent')
    X_processed[:] = imputer.fit_transform(X_processed)

    # ë‚ ì§œ/ì‹œê°„ íŒ¨í„´ ì œê±°
    datetime_cols = []
    for col in X_processed.columns:
        if X_processed[col].dtype == 'object':
            sample_vals = X_processed[col].dropna().head(3).astype(str).tolist()
            has_date_pattern = any(
                len(val) >= 8 and ('-' in val or '/' in val or ':') in val
                for val in sample_vals
            )
            if has_date_pattern:
                datetime_cols.append(col)
    if datetime_cols:
        X_processed = X_processed.drop(columns=datetime_cols)

    # ë²”ì£¼í˜• â†’ ì›í•« ì¸ì½”ë”©
    categorical_cols = [
        col for col in X_processed.columns
        if X_processed[col].dtype == 'object' and X_processed[col].nunique() <= 50
    ]
    if categorical_cols:
        X_processed = pd.get_dummies(X_processed, columns=categorical_cols, drop_first=True)

    # ë¹„ìˆ˜ì¹˜í˜• ì œê±°
    non_numeric = X_processed.select_dtypes(exclude=['number']).columns.tolist()
    if non_numeric:
        X_processed = X_processed.drop(columns=non_numeric)

    print(f"   âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {X_processed.shape}")
    return X_processed

# 4. ì „ì²˜ë¦¬ ì‹¤í–‰
X_train_processed = preprocess_data(X_train_raw, "Train")
X_test_processed = preprocess_data(X_test_raw, "Test")
y_train_processed = y_train_raw.loc[X_train_processed.index]
y_test_processed = y_test_raw.loc[X_test_processed.index]

# 5. ì»¬ëŸ¼ í†µì¼
common_cols = list(set(X_train_processed.columns) & set(X_test_processed.columns))
X_train_final = X_train_processed[common_cols]
X_test_final = X_test_processed[common_cols]

print(f"\nğŸ“Š ì „ì²˜ë¦¬ í›„ ìµœì¢… ë°ì´í„°:")
print(f"   Train: {X_train_final.shape}, Test: {X_test_final.shape}")

# âš–ï¸ ì´í•˜ ëª¨ë¸ í•™ìŠµ/í‰ê°€ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥

# 6. ğŸ“Š ë¶ˆê· í˜• í•´ê²° ë°©ë²•ë“¤ ì •ì˜
print(f"\nâš–ï¸ ë¶ˆê· í˜• í•´ê²° ë°©ë²• ì •ì˜...")

# 6-1. ìƒ˜í”Œë§ ê¸°ë²•ë“¤
def undersample_data(X, y, ratio=0.4, random_state=42):
    """ì–¸ë”ìƒ˜í”Œë§"""
    np.random.seed(random_state)
    
    good_indices = y[y == 0].index
    defect_indices = y[y == 1].index
    
    defect_count = len(defect_indices)
    target_good_count = int(defect_count / ratio * (1 - ratio))
    
    sampled_good_indices = np.random.choice(good_indices, min(target_good_count, len(good_indices)), replace=False)
    final_indices = np.concatenate([sampled_good_indices, defect_indices])
    np.random.shuffle(final_indices)
    
    return X.loc[final_indices], y.loc[final_indices]

def oversample_data(X, y, ratio=0.4, random_state=42):
    """ì˜¤ë²„ìƒ˜í”Œë§"""
    np.random.seed(random_state)
    
    good_indices = y[y == 0].index
    defect_indices = y[y == 1].index
    
    good_count = len(good_indices)
    target_defect_count = int(good_count * ratio / (1 - ratio))
    
    # ë¶€ì¡±í•œ ë§Œí¼ ë³µì œ
    additional_defect = target_defect_count - len(defect_indices)
    if additional_defect > 0:
        sampled_defect_indices = np.random.choice(defect_indices, additional_defect, replace=True)
        all_defect_indices = np.concatenate([defect_indices, sampled_defect_indices])
    else:
        all_defect_indices = defect_indices
    
    final_indices = np.concatenate([good_indices, all_defect_indices])
    np.random.shuffle(final_indices)
    
    return X.loc[final_indices], y.loc[final_indices]

def mixed_sample_data(X, y, ratio=0.4, random_state=42):
    """í˜¼í•© ìƒ˜í”Œë§ (ì–¸ë”+ì˜¤ë²„)"""
    np.random.seed(random_state)
    
    good_indices = y[y == 0].index
    defect_indices = y[y == 1].index
    
    good_count = len(good_indices)
    defect_count = len(defect_indices)
    
    # ëª©í‘œ: ì „ì²´ì˜ 80% í¬ê¸°ë¡œ ì¶•ì†Œí•˜ë©´ì„œ ë¹„ìœ¨ ë§ì¶”ê¸°
    target_total = int((good_count + defect_count) * 0.8)
    target_defect = int(target_total * ratio)
    target_good = target_total - target_defect
    
    # ì–‘í’ˆ ì–¸ë”ìƒ˜í”Œë§
    sampled_good_indices = np.random.choice(good_indices, min(target_good, good_count), replace=False)
    
    # ë¶ˆëŸ‰í’ˆ ì˜¤ë²„ìƒ˜í”Œë§
    if target_defect > defect_count:
        additional_defect = target_defect - defect_count
        sampled_additional_defect = np.random.choice(defect_indices, additional_defect, replace=True)
        all_defect_indices = np.concatenate([defect_indices, sampled_additional_defect])
    else:
        all_defect_indices = np.random.choice(defect_indices, target_defect, replace=False)
    
    final_indices = np.concatenate([sampled_good_indices, all_defect_indices])
    np.random.shuffle(final_indices)
    
    return X.loc[final_indices], y.loc[final_indices]

def synthetic_sample_data(X, y, ratio=0.4, random_state=42):
    """í•©ì„± ìƒ˜í”Œ ìƒì„± (ê°„ë‹¨í•œ SMOTE)"""
    np.random.seed(random_state)
    
    good_data = X[y == 0]
    defect_data = X[y == 1]
    
    good_count = len(good_data)
    target_defect_count = int(good_count * ratio / (1 - ratio))
    additional_defect = target_defect_count - len(defect_data)
    
    if additional_defect > 0:
        # í•©ì„± ìƒ˜í”Œ ìƒì„±
        synthetic_samples = []
        for _ in range(additional_defect):
            # ëœë¤í•˜ê²Œ ë‘ ë¶ˆëŸ‰í’ˆ ìƒ˜í”Œ ì„ íƒ
            idx1, idx2 = np.random.choice(len(defect_data), 2, replace=True)
            sample1 = defect_data.iloc[idx1].values
            sample2 = defect_data.iloc[idx2].values
            
            # ì„ í˜• ë³´ê°„
            alpha = np.random.random()
            synthetic_sample = alpha * sample1 + (1 - alpha) * sample2
            synthetic_samples.append(synthetic_sample)
        
        # í•©ì„± ë°ì´í„° ì¶”ê°€
        synthetic_df = pd.DataFrame(synthetic_samples, columns=X.columns)
        X_synthetic = pd.concat([good_data, defect_data, synthetic_df], ignore_index=True)
        y_synthetic = pd.concat([
            pd.Series([0] * len(good_data)),
            pd.Series([1] * len(defect_data)),
            pd.Series([1] * len(synthetic_samples))
        ], ignore_index=True)
        
        # ì„ê¸°
        shuffle_indices = np.random.permutation(len(X_synthetic))
        return X_synthetic.iloc[shuffle_indices], y_synthetic.iloc[shuffle_indices]
    else:
        return X, y

# 6-2. ê°€ì¤‘ì¹˜ ê³„ì‚° í•¨ìˆ˜
def compute_sample_weights(y, method='balanced'):
    """ìƒ˜í”Œ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    if method == 'balanced':
        class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
        weight_dict = {0: class_weights[0], 1: class_weights[1]}
        return np.array([weight_dict[label] for label in y])
    elif method == 'custom':
        # ë¶ˆëŸ‰í’ˆì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ (ì–‘í’ˆ:ë¶ˆëŸ‰í’ˆ = 1:3)
        return np.array([1 if label == 0 else 3 for label in y])
    else:
        return None

# 7. ğŸ“Š ë‹¤ì–‘í•œ ë¶ˆê· í˜• í•´ê²° ë°©ë²• ì ìš©
print(f"\nğŸ¯ ë‹¤ì–‘í•œ ë¶ˆê· í˜• í•´ê²° ë°©ë²• í…ŒìŠ¤íŠ¸...")

# 7-1. ë°ì´í„° ì¤€ë¹„
methods_data = {}

# ì›ë³¸ ë°ì´í„° (ë¶ˆê· í˜• ê·¸ëŒ€ë¡œ)
methods_data['Original'] = {
    'X': X_train_final.copy(),
    'y': y_train_processed.copy(),
    'description': 'ì›ë³¸ ë¶ˆê· í˜• ë°ì´í„°'
}

# ì–¸ë”ìƒ˜í”Œë§
X_under, y_under = undersample_data(X_train_final, y_train_processed, ratio=0.4)
methods_data['Undersample'] = {
    'X': X_under,
    'y': y_under,
    'description': 'ì–¸ë”ìƒ˜í”Œë§ (4:6 ë¹„ìœ¨)'
}

# ì˜¤ë²„ìƒ˜í”Œë§
X_over, y_over = oversample_data(X_train_final, y_train_processed, ratio=0.4)
methods_data['Oversample'] = {
    'X': X_over,
    'y': y_over,
    'description': 'ì˜¤ë²„ìƒ˜í”Œë§ (4:6 ë¹„ìœ¨)'
}

# í˜¼í•© ìƒ˜í”Œë§
X_mixed, y_mixed = mixed_sample_data(X_train_final, y_train_processed, ratio=0.4)
methods_data['Mixed'] = {
    'X': X_mixed,
    'y': y_mixed,
    'description': 'í˜¼í•© ìƒ˜í”Œë§ (ì–¸ë”+ì˜¤ë²„)'
}

# í•©ì„± ìƒ˜í”Œ
X_synthetic, y_synthetic = synthetic_sample_data(X_train_final, y_train_processed, ratio=0.4)
methods_data['Synthetic'] = {
    'X': X_synthetic,
    'y': y_synthetic,
    'description': 'í•©ì„± ìƒ˜í”Œ ìƒì„± (SMOTE ìœ ì‚¬)'
}

# ìƒ˜í”Œ ê°€ì¤‘ì¹˜ (ì›ë³¸ ë°ì´í„° + ê°€ì¤‘ì¹˜)
sample_weights_balanced = compute_sample_weights(y_train_processed, 'balanced')
sample_weights_custom = compute_sample_weights(y_train_processed, 'custom')

methods_data['Weighted_Balanced'] = {
    'X': X_train_final.copy(),
    'y': y_train_processed.copy(),
    'sample_weight': sample_weights_balanced,
    'description': 'ì›ë³¸ + ê· í˜• ê°€ì¤‘ì¹˜'
}

methods_data['Weighted_Custom'] = {
    'X': X_train_final.copy(),
    'y': y_train_processed.copy(),
    'sample_weight': sample_weights_custom,
    'description': 'ì›ë³¸ + ë¶ˆëŸ‰í’ˆ 3ë°° ê°€ì¤‘ì¹˜'
}

# ê° ë°©ë²•ë³„ ë°ì´í„° ë¶„í¬ ì¶œë ¥
print(f"\nğŸ“Š ë¶ˆê· í˜• í•´ê²° ë°©ë²•ë³„ ë°ì´í„° ë¶„í¬:")
print("-" * 70)
for method, data in methods_data.items():
    y_counts = data['y'].value_counts().sort_index()
    total = len(data['y'])
    good_pct = y_counts.get(0, 0) / total * 100
    defect_pct = y_counts.get(1, 0) / total * 100
    
    weight_info = ""
    if 'sample_weight' in data:
        weight_info = " (ê°€ì¤‘ì¹˜ ì ìš©)"
    
    print(f"{method:15s}: {total:6,}ê°œ | ì–‘í’ˆ: {y_counts.get(0, 0):5,}({good_pct:4.1f}%) | "
          f"ë¶ˆëŸ‰í’ˆ: {y_counts.get(1, 0):5,}({defect_pct:4.1f}%){weight_info}")

# 8. ğŸ“Š ëª¨ë¸ ì •ì˜ (ë¶ˆê· í˜• ëŒ€ì‘ ì˜µì…˜ í¬í•¨)
print(f"\nğŸ¤– ëª¨ë¸ ì •ì˜...")

def get_models():
    """ë‹¤ì–‘í•œ ë¶ˆê· í˜• ëŒ€ì‘ ì˜µì…˜ì„ ê°€ì§„ ëª¨ë¸ë“¤"""
    models = {
        'RandomForest': RandomForestClassifier(
            n_estimators=100, max_depth=10, random_state=42, n_jobs=-1
        ),
        'RandomForest_Balanced': RandomForestClassifier(
            n_estimators=100, max_depth=10, random_state=42, n_jobs=-1, class_weight='balanced'
        ),
        'GradientBoosting': GradientBoostingClassifier(
            n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42
        ),
        'LogisticRegression': LogisticRegression(
            random_state=42, max_iter=1000
        ),
        'LogisticRegression_Balanced': LogisticRegression(
            random_state=42, max_iter=1000, class_weight='balanced'
        )
    }
    
    if XGBOOST_AVAILABLE:
        models['XGBoost'] = xgb.XGBClassifier(
            n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, eval_metric='logloss'
        )
        models['XGBoost_Balanced'] = xgb.XGBClassifier(
            n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, eval_metric='logloss'
        )
    
    if LIGHTGBM_AVAILABLE:
        models['LightGBM'] = lgb.LGBMClassifier(
            n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1
        )
        models['LightGBM_Balanced'] = lgb.LGBMClassifier(
            n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1, class_weight='balanced'
        )
    
    return models

# 9. ğŸ‹ï¸ ëŒ€ê·œëª¨ ì‹¤í—˜ ì‹¤í–‰
print(f"\nğŸ‹ï¸ ë¶ˆê· í˜• í•´ê²° ë°©ë²• vs ëª¨ë¸ ì¡°í•© ì‹¤í—˜...")
print("ì´ê²ƒì€ ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤... â³")

# ê²°ê³¼ ì €ì¥
all_results = {}
scaler = StandardScaler()

# ìŠ¤ì¼€ì¼ë§ì´ í•„ìš”í•œ ëª¨ë¸ë“¤
scaling_models = ['LogisticRegression', 'LogisticRegression_Balanced']

models = get_models()

for balance_method, balance_data in methods_data.items():
    print(f"\nğŸ”„ {balance_method} ë°©ë²• í…ŒìŠ¤íŠ¸...")
    
    X_train = balance_data['X']
    y_train = balance_data['y']
    sample_weight = balance_data.get('sample_weight', None)
    
    # ìŠ¤ì¼€ì¼ë§
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test_final)
    
    for model_name, model in models.items():
        try:
            combination_name = f"{balance_method}_{model_name}"
            
            # ìŠ¤ì¼€ì¼ë§ ë°ì´í„° ì„ íƒ
            if model_name in scaling_models:
                X_train_use = X_train_scaled
                X_test_use = X_test_scaled
            else:
                X_train_use = X_train
                X_test_use = X_test_final
            
            # XGBoost/LightGBMì˜ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì²˜ë¦¬
            if 'Balanced' in model_name and ('XGBoost' in model_name or 'LightGBM' in model_name):
                if 'XGBoost' in model_name:
                    # XGBoostì—ì„œëŠ” scale_pos_weight ì‚¬ìš©
                    pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
                    model.set_params(scale_pos_weight=pos_weight)
                elif 'LightGBM' in model_name:
                    # LightGBMì€ ì´ë¯¸ class_weight='balanced'ë¡œ ì„¤ì •ë¨
                    pass
            
            # ëª¨ë¸ í•™ìŠµ (ê°€ì¤‘ì¹˜ê°€ ìˆìœ¼ë©´ ì ìš©)
            if sample_weight is not None and hasattr(model, 'fit') and 'sample_weight' in model.fit.__code__.co_varnames:
                model.fit(X_train_use, y_train, sample_weight=sample_weight)
            else:
                model.fit(X_train_use, y_train)
            
            # ì˜ˆì¸¡
            test_pred = model.predict(X_test_use)
            test_proba = model.predict_proba(X_test_use)[:, 1] if hasattr(model, 'predict_proba') else None
            
            # ì„±ëŠ¥ ê³„ì‚°
            accuracy = accuracy_score(y_test_processed, test_pred)
            precision = precision_score(y_test_processed, test_pred, zero_division=0)
            recall = recall_score(y_test_processed, test_pred, zero_division=0)
            f1 = f1_score(y_test_processed, test_pred, zero_division=0)
            
            # ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì •í™•ë„
            actual_defect_rate = (y_test_processed == 1).sum() / len(y_test_processed) * 100
            predicted_defect_rate = (test_pred == 1).sum() / len(test_pred) * 100
            defect_rate_error = abs(actual_defect_rate - predicted_defect_rate)
            
            # ê²°ê³¼ ì €ì¥
            all_results[combination_name] = {
                'balance_method': balance_method,
                'model': model_name,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'actual_defect_rate': actual_defect_rate,
                'predicted_defect_rate': predicted_defect_rate,
                'defect_rate_error': defect_rate_error,
                'train_size': len(X_train),
                'description': balance_data['description']
            }
            
            print(f"   âœ… {model_name:20s}: ì •í™•ë„ {accuracy:.4f}, ë¶ˆëŸ‰ë¥ ì˜¤ì°¨ {defect_rate_error:.2f}%p")
            
        except Exception as e:
            print(f"   âŒ {model_name}: ì‹¤íŒ¨ - {str(e)}")
            continue

# 10. ğŸ“Š ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”
print(f"\nğŸ“Š ì¢…í•© ê²°ê³¼ ë¶„ì„...")

results_df = pd.DataFrame(all_results).T
results_df = results_df.sort_values('defect_rate_error', ascending=True)

print(f"\nğŸ† ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì •í™•ë„ TOP 10:")
print("="*120)
print(f"{'ìˆœìœ„':>2} {'ë¶ˆê· í˜•í•´ê²°ë°©ë²•':15} {'ëª¨ë¸':20} {'ì •í™•ë„':>8} {'ì •ë°€ë„':>8} {'ì¬í˜„ìœ¨':>8} {'F1':>6} {'ë¶ˆëŸ‰ë¥ ì˜¤ì°¨':>8}")
print("-"*120)

for i, (combination, row) in enumerate(results_df.head(10).iterrows(), 1):
    print(f"{i:2d}. {row['balance_method']:15s} {row['model']:20s} "
          f"{row['accuracy']:8.4f} {row['precision']:8.4f} {row['recall']:8.4f} "
          f"{row['f1']:6.4f} {row['defect_rate_error']:7.2f}%p")

# 11. ìƒì„¸ ì‹œê°í™”
fig, axes = plt.subplots(3, 3, figsize=(20, 18))

# 11-1. ë¶ˆê· í˜• í•´ê²° ë°©ë²•ë³„ í‰ê·  ì„±ëŠ¥
method_performance = results_df.groupby('balance_method').agg({
    'defect_rate_error': 'mean',
    'accuracy': 'mean',
    'f1': 'mean'
}).round(4)

ax1 = axes[0, 0]
method_names = method_performance.index
x_pos = np.arange(len(method_names))
bars = ax1.bar(x_pos, method_performance['defect_rate_error'], alpha=0.8, color='skyblue')
ax1.set_title('ë¶ˆê· í˜• í•´ê²° ë°©ë²•ë³„ í‰ê·  ë¶ˆëŸ‰ë¥  ì˜¤ì°¨', fontweight='bold')
ax1.set_xlabel('ë¶ˆê· í˜• í•´ê²° ë°©ë²•')
ax1.set_ylabel('ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ (%p)')
ax1.set_xticks(x_pos)
ax1.set_xticklabels(method_names, rotation=45, ha='right')
ax1.grid(axis='y', alpha=0.3)

# 11-2. ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥
model_performance = results_df.groupby('model').agg({
    'defect_rate_error': 'mean',
    'accuracy': 'mean',
    'f1': 'mean'
}).round(4)

ax2 = axes[0, 1]
model_names = model_performance.index
x_pos = np.arange(len(model_names))
bars = ax2.bar(x_pos, model_performance['defect_rate_error'], alpha=0.8, color='lightgreen')
ax2.set_title('ëª¨ë¸ë³„ í‰ê·  ë¶ˆëŸ‰ë¥  ì˜¤ì°¨', fontweight='bold')
ax2.set_xlabel('ëª¨ë¸')
ax2.set_ylabel('ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ (%p)')
ax2.set_xticks(x_pos)
ax2.set_xticklabels(model_names, rotation=45, ha='right')
ax2.grid(axis='y', alpha=0.3)

# 11-3. ë¶ˆê· í˜• í•´ê²° ë°©ë²•ë³„ íˆíŠ¸ë§µ
ax3 = axes[0, 2]
pivot_data = results_df.pivot_table(values='defect_rate_error', 
                                   index='balance_method', 
                                   columns='model', 
                                   aggfunc='mean')
sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='YlOrRd_r', ax=ax3)
ax3.set_title('ë¶ˆê· í˜•ë°©ë²• Ã— ëª¨ë¸ ë¶ˆëŸ‰ë¥  ì˜¤ì°¨', fontweight='bold')
ax3.set_xlabel('ëª¨ë¸')
ax3.set_ylabel('ë¶ˆê· í˜• í•´ê²° ë°©ë²•')

# 11-4. ì •í™•ë„ vs ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ ìŠ¤ìºí„°
ax4 = axes[1, 0]
scatter = ax4.scatter(results_df['defect_rate_error'], results_df['accuracy'], 
                     c=results_df['f1'], cmap='viridis', s=50, alpha=0.7)
ax4.set_xlabel('ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ (%p)')
ax4.set_ylabel('ì •í™•ë„')
ax4.set_title('ì •í™•ë„ vs ë¶ˆëŸ‰ë¥  ì˜¤ì°¨', fontweight='bold')
ax4.grid(True, alpha=0.3)
plt.colorbar(scatter, ax=ax4, label='F1 Score')

# 11-5. TOP 5 ì¡°í•© ìƒì„¸ ë¹„êµ
ax5 = axes[1, 1]
top_5 = results_df.head(5)
metrics = ['accuracy', 'precision', 'recall', 'f1']
x = np.arange(len(top_5))
width = 0.2

for i, metric in enumerate(metrics):
    ax5.bar(x + i*width, top_5[metric], width, label=metric.capitalize(), alpha=0.8)

ax5.set_title('TOP 5 ì¡°í•© ì„±ëŠ¥ ë¹„êµ', fontweight='bold')
ax5.set_xlabel('ì¡°í•© (ë¶ˆê· í˜•ë°©ë²•_ëª¨ë¸)')
ax5.set_ylabel('ì„±ëŠ¥ ì ìˆ˜')
ax5.set_xticks(x + width * 1.5)
ax5.set_xticklabels([f"{row['balance_method'][:8]}\n{row['model'][:12]}" 
                     for _, row in top_5.iterrows()], fontsize=8)
ax5.legend()
ax5.grid(axis='y', alpha=0.3)

# 11-6. ë¶ˆê· í˜• í•´ê²° ë°©ë²•ë³„ ë°ì´í„° ë¶„í¬ ë³€í™”
ax6 = axes[1, 2]
method_samples = []
method_labels = []
good_ratios = []
defect_ratios = []

for method, data in methods_data.items():
    if 'Weighted' not in method:  # ê°€ì¤‘ì¹˜ ë°©ë²•ì€ ë°ì´í„° í¬ê¸°ê°€ ê°™ìœ¼ë¯€ë¡œ ì œì™¸
        y_counts = data['y'].value_counts().sort_index()
        total = len(data['y'])
        good_ratios.append(y_counts.get(0, 0) / total * 100)
        defect_ratios.append(y_counts.get(1, 0) / total * 100)
        method_labels.append(method)

x_pos = np.arange(len(method_labels))
width = 0.35

ax6.bar(x_pos - width/2, good_ratios, width, label='ì–‘í’ˆ ë¹„ìœ¨', alpha=0.8, color='lightblue')
ax6.bar(x_pos + width/2, defect_ratios, width, label='ë¶ˆëŸ‰í’ˆ ë¹„ìœ¨', alpha=0.8, color='lightcoral')
ax6.set_title('ë¶ˆê· í˜• í•´ê²° ë°©ë²•ë³„ í´ë˜ìŠ¤ ë¹„ìœ¨', fontweight='bold')
ax6.set_xlabel('ë¶ˆê· í˜• í•´ê²° ë°©ë²•')
ax6.set_ylabel('ë¹„ìœ¨ (%)')
ax6.set_xticks(x_pos)
ax6.set_xticklabels(method_labels, rotation=45, ha='right')
ax6.legend()
ax6.grid(axis='y', alpha=0.3)

# 11-7. ì •ë°€ë„ vs ì¬í˜„ìœ¨ íŠ¸ë ˆì´ë“œì˜¤í”„
ax7 = axes[2, 0]
scatter = ax7.scatter(results_df['recall'], results_df['precision'], 
                     c=results_df['defect_rate_error'], cmap='RdYlGn_r', s=50, alpha=0.7)
ax7.set_xlabel('ì¬í˜„ìœ¨ (Recall)')
ax7.set_ylabel('ì •ë°€ë„ (Precision)')
ax7.set_title('ì •ë°€ë„ vs ì¬í˜„ìœ¨ (ìƒ‰ìƒ: ë¶ˆëŸ‰ë¥  ì˜¤ì°¨)', fontweight='bold')
ax7.grid(True, alpha=0.3)
plt.colorbar(scatter, ax=ax7, label='ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ (%p)')

# ìµœê³  ì„±ëŠ¥ í¬ì¸íŠ¸ í‘œì‹œ
best_idx = results_df['defect_rate_error'].idxmin()
best_recall = results_df.loc[best_idx, 'recall']
best_precision = results_df.loc[best_idx, 'precision']
ax7.scatter(best_recall, best_precision, color='red', s=100, marker='*', 
           label=f'ìµœê³ ì„±ëŠ¥\n({results_df.loc[best_idx, "balance_method"][:8]})')
ax7.legend()

# 11-8. ìƒ˜í”Œë§ ë°©ë²• vs ê°€ì¤‘ì¹˜ ë°©ë²• ë¹„êµ
ax8 = axes[2, 1]
sampling_methods = ['Original', 'Undersample', 'Oversample', 'Mixed', 'Synthetic']
weighting_methods = ['Weighted_Balanced', 'Weighted_Custom']

sampling_performance = results_df[results_df['balance_method'].isin(sampling_methods)].groupby('balance_method')['defect_rate_error'].mean()
weighting_performance = results_df[results_df['balance_method'].isin(weighting_methods)].groupby('balance_method')['defect_rate_error'].mean()

# í‰ê·  ì„±ëŠ¥ ë¹„êµ
sampling_avg = sampling_performance.mean()
weighting_avg = weighting_performance.mean()

categories = ['ìƒ˜í”Œë§ ë°©ë²•\ní‰ê· ', 'ê°€ì¤‘ì¹˜ ë°©ë²•\ní‰ê· ']
values = [sampling_avg, weighting_avg]
colors = ['lightblue', 'lightgreen']

bars = ax8.bar(categories, values, color=colors, alpha=0.8)
ax8.set_title('ìƒ˜í”Œë§ vs ê°€ì¤‘ì¹˜ ë°©ë²• ë¹„êµ', fontweight='bold')
ax8.set_ylabel('í‰ê·  ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ (%p)')
ax8.grid(axis='y', alpha=0.3)

# ê°’ í‘œì‹œ
for bar, val in zip(bars, values):
    ax8.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, 
            f'{val:.2f}%p', ha='center', va='bottom', fontweight='bold')

# 11-9. ìµœê³  ì„±ëŠ¥ ì¡°í•©ì˜ í˜¼ë™í–‰ë ¬
ax9 = axes[2, 2]
best_combination = results_df.index[0]
best_method = results_df.loc[best_combination, 'balance_method']
best_model_name = results_df.loc[best_combination, 'model']

# ìµœê³  ì„±ëŠ¥ ì¡°í•©ìœ¼ë¡œ ë‹¤ì‹œ í•™ìŠµí•˜ì—¬ í˜¼ë™í–‰ë ¬ ìƒì„±
best_data = methods_data[best_method]
best_models = get_models()
best_model = best_models[best_model_name]

# ìŠ¤ì¼€ì¼ë§
if best_model_name in scaling_models:
    scaler_best = StandardScaler()
    X_train_best = scaler_best.fit_transform(best_data['X'])
    X_test_best = scaler_best.transform(X_test_final)
else:
    X_train_best = best_data['X']
    X_test_best = X_test_final

# í•™ìŠµ ë° ì˜ˆì¸¡
sample_weight_best = best_data.get('sample_weight', None)

# XGBoost/LightGBM í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì²˜ë¦¬
if 'Balanced' in best_model_name and 'XGBoost' in best_model_name:
    pos_weight = (best_data['y'] == 0).sum() / (best_data['y'] == 1).sum()
    best_model.set_params(scale_pos_weight=pos_weight)

if sample_weight_best is not None and hasattr(best_model, 'fit') and 'sample_weight' in best_model.fit.__code__.co_varnames:
    best_model.fit(X_train_best, best_data['y'], sample_weight=sample_weight_best)
else:
    best_model.fit(X_train_best, best_data['y'])

best_pred = best_model.predict(X_test_best)
cm = confusion_matrix(y_test_processed, best_pred)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax9,
            xticklabels=['ì–‘í’ˆ(0)', 'ë¶ˆëŸ‰í’ˆ(1)'], yticklabels=['ì–‘í’ˆ(0)', 'ë¶ˆëŸ‰í’ˆ(1)'])
ax9.set_title(f'ìµœê³ ì„±ëŠ¥ ì¡°í•© í˜¼ë™í–‰ë ¬\n{best_method} + {best_model_name}', fontweight='bold')
ax9.set_xlabel('ì˜ˆì¸¡')
ax9.set_ylabel('ì‹¤ì œ')

plt.tight_layout()
plt.suptitle('ğŸ¯ ë¶ˆê· í˜• í•´ê²° ë°©ë²• ì¢…í•© ë¹„êµ ë¶„ì„', fontsize=16, fontweight='bold', y=0.98)
plt.show()

# 12. ğŸ“‹ ìƒì„¸ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸
print(f"\nğŸ“‹ ìƒì„¸ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸")
print("="*60)

# 12-1. ìµœê³  ì„±ëŠ¥ ì¡°í•© ë¶„ì„
best_3 = results_df.head(3)
print(f"ğŸ† TOP 3 ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡ ì¡°í•©:")
for i, (combination, row) in enumerate(best_3.iterrows(), 1):
    print(f"   {i}. {row['balance_method']} + {row['model']}")
    print(f"      ğŸ¯ ë¶ˆëŸ‰ë¥  ì˜¤ì°¨: {row['defect_rate_error']:.2f}%p")
    print(f"      ğŸ“Š ì •í™•ë„: {row['accuracy']:.4f}")
    print(f"      ğŸ”§ í›ˆë ¨ ë°ì´í„°: {row['train_size']:,}ê°œ")

# 12-2. ë¶ˆê· í˜• í•´ê²° ë°©ë²• íš¨ê³¼ ë¶„ì„
print(f"\nğŸ“Š ë¶ˆê· í˜• í•´ê²° ë°©ë²•ë³„ íš¨ê³¼:")
method_avg = method_performance.sort_values('defect_rate_error')
print(f"   ğŸ¥‡ ìµœê³ : {method_avg.index[0]} (í‰ê·  ì˜¤ì°¨: {method_avg.iloc[0]['defect_rate_error']:.2f}%p)")
print(f"   ğŸ¥ˆ 2ìœ„: {method_avg.index[1]} (í‰ê·  ì˜¤ì°¨: {method_avg.iloc[1]['defect_rate_error']:.2f}%p)")
print(f"   ğŸ¥‰ 3ìœ„: {method_avg.index[2]} (í‰ê·  ì˜¤ì°¨: {method_avg.iloc[2]['defect_rate_error']:.2f}%p)")

# ì›ë³¸ ëŒ€ë¹„ ê°œì„  íš¨ê³¼
original_avg = method_avg.loc['Original', 'defect_rate_error']
best_method_avg = method_avg.iloc[0]['defect_rate_error']
improvement = original_avg - best_method_avg
print(f"   ğŸ“ˆ ì›ë³¸ ëŒ€ë¹„ ê°œì„ : {improvement:.2f}%p ({improvement/original_avg*100:.1f}% ê°œì„ )")

# 12-3. ëª¨ë¸ë³„ íš¨ê³¼ ë¶„ì„
print(f"\nğŸ¤– ëª¨ë¸ë³„ ë¶ˆê· í˜• ëŒ€ì‘ íš¨ê³¼:")
model_avg = model_performance.sort_values('defect_rate_error')
print(f"   ğŸ¯ ìµœê³  ëª¨ë¸: {model_avg.index[0]} (í‰ê·  ì˜¤ì°¨: {model_avg.iloc[0]['defect_rate_error']:.2f}%p)")

# Balanced ë²„ì „ê³¼ ì¼ë°˜ ë²„ì „ ë¹„êµ
balanced_models = [m for m in model_avg.index if 'Balanced' in m]
regular_models = [m for m in model_avg.index if m.replace('_Balanced', '') in [b.replace('_Balanced', '') for b in balanced_models]]

print(f"   âš–ï¸ class_weight='balanced' íš¨ê³¼:")
for regular in regular_models:
    balanced = regular + '_Balanced'
    if balanced in model_avg.index:
        regular_score = model_avg.loc[regular, 'defect_rate_error'] if regular in model_avg.index else None
        balanced_score = model_avg.loc[balanced, 'defect_rate_error']
        if regular_score:
            improvement = regular_score - balanced_score
            print(f"      {regular}: {improvement:+.2f}%p ({'ê°œì„ ' if improvement > 0 else 'ì•…í™”'})")

# 12-4. ìƒ˜í”Œë§ vs ê°€ì¤‘ì¹˜ ë°©ë²• ê²°ë¡ 
sampling_results = results_df[results_df['balance_method'].isin(sampling_methods)]
weighting_results = results_df[results_df['balance_method'].isin(weighting_methods)]

sampling_best = sampling_results['defect_rate_error'].min()
weighting_best = weighting_results['defect_rate_error'].min()

print(f"\nâš–ï¸ ìƒ˜í”Œë§ vs ê°€ì¤‘ì¹˜ ë°©ë²• ê²°ë¡ :")
print(f"   ğŸ“Š ìƒ˜í”Œë§ ë°©ë²• ìµœê³ : {sampling_best:.2f}%p")
print(f"   ğŸ‹ï¸ ê°€ì¤‘ì¹˜ ë°©ë²• ìµœê³ : {weighting_best:.2f}%p")
if sampling_best < weighting_best:
    print(f"   ğŸ† ê²°ë¡ : ìƒ˜í”Œë§ ë°©ë²•ì´ {weighting_best - sampling_best:.2f}%p ë” ìš°ìˆ˜")
else:
    print(f"   ğŸ† ê²°ë¡ : ê°€ì¤‘ì¹˜ ë°©ë²•ì´ {sampling_best - weighting_best:.2f}%p ë” ìš°ìˆ˜")

# 12-5. ë°ì´í„° í¬ê¸°ë³„ íš¨ê³¼ ë¶„ì„
print(f"\nğŸ“ ë°ì´í„° í¬ê¸°ë³„ íš¨ê³¼:")
size_analysis = results_df.groupby('balance_method').agg({
    'train_size': 'first',
    'defect_rate_error': 'mean'
}).sort_values('defect_rate_error')

for method, row in size_analysis.iterrows():
    if method != 'Original':
        original_size = size_analysis.loc['Original', 'train_size']
        size_change = row['train_size'] - original_size
        size_change_pct = size_change / original_size * 100
        print(f"   {method:15s}: í¬ê¸°ë³€í™” {size_change:+6,}ê°œ ({size_change_pct:+5.1f}%) â†’ ì˜¤ì°¨ {row['defect_rate_error']:.2f}%p")

# 12-6. ìµœì¢… ì¶”ì²œ
print(f"\nğŸ’¡ ìµœì¢… ì¶”ì²œ:")
ultimate_best = results_df.iloc[0]
print(f"   ğŸ¯ ìµœìš°ì„  ì¶”ì²œ: {ultimate_best['balance_method']} + {ultimate_best['model']}")
print(f"      ğŸ“Š ë¶ˆëŸ‰ë¥  ì˜¤ì°¨: {ultimate_best['defect_rate_error']:.2f}%p")
print(f"      ğŸ“ˆ ì •í™•ë„: {ultimate_best['accuracy']:.4f}")
print(f"      ğŸ”§ F1-Score: {ultimate_best['f1']:.4f}")
print(f"      ğŸ“ ì„¤ëª…: {ultimate_best['description']}")

# ì‹¤ìš©ì  ê´€ì ì—ì„œì˜ ì¶”ì²œ
practical_threshold = 1.0  # 1%p ì´í•˜ ì˜¤ì°¨
practical_candidates = results_df[results_df['defect_rate_error'] <= practical_threshold]

if len(practical_candidates) > 0:
    print(f"\nâœ¨ ì‹¤ìš©ì  ê´€ì  (ë¶ˆëŸ‰ë¥  ì˜¤ì°¨ {practical_threshold}%p ì´í•˜):")
    # ì´ ì¤‘ì—ì„œ ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²• ì¶”ì²œ
    simplicity_order = ['Original', 'Weighted_Balanced', 'Weighted_Custom', 'Undersample', 'Oversample', 'Mixed', 'Synthetic']
    
    for simple_method in simplicity_order:
        simple_candidates = practical_candidates[practical_candidates['balance_method'] == simple_method]
        if len(simple_candidates) > 0:
            best_simple = simple_candidates.iloc[0]
            print(f"   ğŸ¯ ê°„ë‹¨í•œ ì¶”ì²œ: {best_simple['balance_method']} + {best_simple['model']}")
            print(f"      ğŸ’¼ ì¥ì : êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì˜¤ì°¨ {best_simple['defect_rate_error']:.2f}%p")
            break

print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥:")
print(f"   - all_results: ì „ì²´ ì‹¤í—˜ ê²°ê³¼")
print(f"   - results_df: ì •ë¦¬ëœ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„")
print(f"   - methods_data: ê° ë¶ˆê· í˜• í•´ê²° ë°©ë²•ë³„ ë°ì´í„°")
print(f"   - method_performance: ë°©ë²•ë³„ í‰ê·  ì„±ëŠ¥")
print(f"   - model_performance: ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥")

print(f"\nâœ… ë¶ˆê· í˜• í•´ê²° ë°©ë²• ë¹„êµ ë¶„ì„ ì™„ë£Œ! ğŸ¯")

# 13. ì‹¤ì œ ì ìš© ê°€ì´ë“œ
print(f"\nğŸ“š ì‹¤ì œ ì ìš© ê°€ì´ë“œ:")
print(f"="*50)
print(f"1ï¸âƒ£ ë¹ ë¥¸ ì ìš©: {ultimate_best['balance_method']} + {ultimate_best['model']}")
print(f"2ï¸âƒ£ ë°ì´í„°ê°€ ë§ìœ¼ë©´: ì–¸ë”ìƒ˜í”Œë§ ë°©ë²• ê³ ë ¤")
print(f"3ï¸âƒ£ ë°ì´í„°ê°€ ì ìœ¼ë©´: ì˜¤ë²„ìƒ˜í”Œë§ ë˜ëŠ” í•©ì„± ìƒ˜í”Œ ê³ ë ¤") 
print(f"4ï¸âƒ£ êµ¬í˜„ì´ ê°„ë‹¨í•´ì•¼ í•˜ë©´: class_weight='balanced' ì˜µì…˜ í™œìš©")
print(f"5ï¸âƒ£ ë¶ˆëŸ‰ë¥ ì´ ë§¤ìš° ë‚®ìœ¼ë©´: ê°€ì¤‘ì¹˜ ë°©ë²•ì´ ë” ì•ˆì „í•  ìˆ˜ ìˆìŒ")
print(f"6ï¸âƒ£ ì‹¤ì‹œê°„ ì˜ˆì¸¡ì´ í•„ìš”í•˜ë©´: ê°€ë²¼ìš´ ëª¨ë¸ + ê°„ë‹¨í•œ ë¶ˆê· í˜• í•´ê²° ë°©ë²•")

print(f"\nğŸ‰ ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")